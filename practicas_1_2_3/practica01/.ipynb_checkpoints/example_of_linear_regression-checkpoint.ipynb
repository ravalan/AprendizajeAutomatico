{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic example of regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import needed packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy\n",
    "from sklearn import linear_model\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn import pipeline\n",
    "from matplotlib import pyplot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definition of useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------\n",
    "def f(x):\n",
    "    return numpy.sin( 2 * numpy.pi * x )\n",
    "# --------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------\n",
    "def g(x):\n",
    "    return f(x) + 0.25*numpy.random.randn( len(x) )\n",
    "# --------------------------------------------------\n",
    "\n",
    "# --------------------------------------------------\n",
    "def my_error(real,estimation):\n",
    "    temp_ = real - estimation\n",
    "    return numpy.sqrt( 2 * numpy.dot(temp_,temp_) / len(temp_) ) # This method computes the Root Mean Square (RMS) error\n",
    "    # return 0.5 * numpy.dot(temp_,temp_) / len(temp_) # This computes the Mean Square Error (MSE)\n",
    "# --------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants to be modified for changing the behaviour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_samples=8\n",
    "max_degree=12\n",
    "verbose=True\n",
    "intermediate_graphics=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generation of the true function for representing it.\n",
    "zx = numpy.linspace(0.0,1.0,1000)\n",
    "zy = f(zx)\n",
    "zx_mat = zx.reshape( len(zx), 1 ) # Converts zx to a matrix with one column. It is needed later in some functions.\n",
    "\n",
    "# Computation of the limits on y-axis for representing the data.\n",
    "min_y=zy.min()\n",
    "max_y=zy.max()\n",
    "dy = max_y-min_y\n",
    "min_y = min_y - 0.1 * dy\n",
    "max_y = max_y + 0.1 * dy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generation of the training-set and the test-set\n",
    "# Values for x-axis equally spaced\n",
    "#X_train = numpy.linspace( 0.05, 0.95, num_samples )\n",
    "# Purely random values for x-axis, choose this for observing the behaviour \n",
    "# of the technique with few samples in the training set\n",
    "X_train = numpy.random.rand(num_samples)\n",
    "X_test = numpy.random.rand( min( 1000, num_samples*10 ) ) # Enough values for the x-axis for the test-set\n",
    "\n",
    "# Computation the funcion with noise. See the definition of g() above.\n",
    "Y_train = g(X_train)\n",
    "Y_test  = g(X_test)\n",
    "\n",
    "# Computation of the true function. See the definition of f() above.\n",
    "Y_train_true = f(X_train)\n",
    "Y_test_true  = f(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This is necessary for the fit method, then, accessing one column of matrix X_train_mat is X_train_mat[:,column]\n",
    "# X_train is also used for representing the scatter-plot.\n",
    "X_train_mat = X_train.reshape( len(X_train), 1 )\n",
    "X_test_mat  =  X_test.reshape( len(X_test),  1 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the regression for different degrees "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Preparation of the array for maintaining the evolution of the error.\n",
    "error_polynomial = numpy.ones( [max_degree+1,2] )\n",
    "\n",
    "for degree in range(max_degree+1):\n",
    "    #\n",
    "    # Creation of the object for transforming the input variables to a polynomial combination of them.\n",
    "    #\n",
    "    poly = PolynomialFeatures( degree = degree )\n",
    "    #\n",
    "    # PolynomialFeatures.fit_transform() needs a bidimensional array or matrix, with as many rows as samples and as many columns as the dime\n",
    "    # That's why we do the reshape() some lines above.\n",
    "    #\n",
    "    X_  = poly.fit_transform( X_train_mat )\n",
    "    zx_ = poly.fit_transform( zx_mat )\n",
    "    #\n",
    "    # Creation of an object of the class LinearRegresion.\n",
    "    # Choose one of the following according to the run you are testing.\n",
    "    # You can test different values of alpha in the Ridge Linear Regression model.\n",
    "    #\n",
    "    linear_regressor = linear_model.LinearRegression( fit_intercept=False )\n",
    "    #linear_regressor = linear_model.Ridge( alpha=0.001, fit_intercept=False )\n",
    "    #\n",
    "    # The fit() method trains the model.\n",
    "    # The transformed input samples are used in order to achieve\n",
    "    # a polynomial regressor by using a linear one.\n",
    "    #\n",
    "    linear_regressor.fit( X_, Y_train )\n",
    "\n",
    "    if verbose:\n",
    "        print( 'Polynomial regression of degree %d: ' % degree )\n",
    "        print( 'Intercept: ' + str(linear_regressor.intercept_) )\n",
    "        print( 'Coef.....: ' + str(linear_regressor.coef_ ) )\n",
    "\n",
    "    if intermediate_graphics:\n",
    "        #pyplot.figure(degree+1)\n",
    "        pyplot.figure( figsize=(10,10) )\n",
    "        pyplot.title( \"Polynomial regression example 1 with degree = %d\" % degree )\n",
    "        pyplot.xlabel( \"x\" )\n",
    "        pyplot.ylabel( \"sin(2*PI*x)\" )\n",
    "        plot1 = pyplot.plot( zx, zy, c='g' )\n",
    "        plot2 = pyplot.plot( X_train, Y_train, 'ro' )\n",
    "        plot3 = pyplot.plot( zx, linear_regressor.predict(zx_), c='m' )\n",
    "        pyplot.ylim( min_y, max_y )\n",
    "        pyplot.show()\n",
    "        \n",
    "    error_polynomial[degree][0] = my_error( Y_train_true, linear_regressor.predict( X_ ) )\n",
    "    error_polynomial[degree][1] = my_error( Y_test_true,  linear_regressor.predict( poly.fit_transform(X_test_mat) ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print the evolution of the error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if verbose:\n",
    "    print( \" RMS for different degrees of the polynomial features. \\n\")\n",
    "    print( \"   DEGREE    ERROR ON TRAINING          ERROR ON TEST \" )\n",
    "    print( \"------------------------------------------------------\" )\n",
    "    for degree in range(len(error_polynomial)):\n",
    "        print( \" %6d      %17.10f      %17.10f\" % (degree, error_polynomial[degree][0], error_polynomial[degree][1] ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the evolution of the error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Finally, we represent the evolution of the error as the degree of the polynomial transformation of input samples grows.\n",
    "#\n",
    "pyplot.figure( figsize=(15,10))\n",
    "pyplot.title( \"Evolution of Root Mean Square (RMS) error\" )\n",
    "pyplot.xlabel( \"Degree\" )\n",
    "pyplot.ylabel( \"RMS\" )\n",
    "pyplot.grid()\n",
    "#\n",
    "artists=[]\n",
    "labels=[]\n",
    "#\n",
    "plot1 = pyplot.plot( numpy.arange(len(error_polynomial)), error_polynomial[:,0], c='b' )\n",
    "artists.append( plot1[0] )\n",
    "labels.append( \"Error on training set \" )\n",
    "#\n",
    "plot2 = pyplot.plot( numpy.arange(len(error_polynomial)), error_polynomial[:,1], c='r' )\n",
    "artists.append( plot2[0] )\n",
    "labels.append( \"Error on test set \" )\n",
    "#\n",
    "dy = error_polynomial[:,1].max()\n",
    "pyplot.ylim( -0.1*dy, 1.1*dy )\n",
    "#\n",
    "pyplot.legend( artists, labels )\n",
    "#\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
